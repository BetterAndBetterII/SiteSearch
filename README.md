# SiteSearch çˆ¬è™«ç³»ç»Ÿ

SiteSearch æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„ç½‘ç«™çˆ¬å–å’Œæœç´¢ç³»ç»Ÿï¼Œç”¨äºå¯¹ç½‘ç«™å†…å®¹è¿›è¡Œçˆ¬å–ã€æ¸…æ´—ã€ç´¢å¼•å’Œæ£€ç´¢ã€‚

## åŠŸèƒ½ç‰¹ç‚¹

- **é«˜æ•ˆçˆ¬å–**ï¼šæ”¯æŒå¤šç§çˆ¬è™«å¼•æ“ï¼ŒåŒ…æ‹¬æœ¬åœ°HTTPXçˆ¬è™«å’ŒFirecrawläº‘æœåŠ¡
- **æ™ºèƒ½æ¸…æ´—**ï¼šå¤šç§å†…å®¹æ¸…æ´—ç­–ç•¥ï¼Œé€‚åº”ä¸åŒç±»å‹çš„ç½‘é¡µ
- **çµæ´»é…ç½®**ï¼šå¯è‡ªå®šä¹‰çˆ¬å–æ·±åº¦ã€é€Ÿç‡ã€è¿‡æ»¤è§„åˆ™ç­‰
- **ç½‘ç«™åœ°å›¾æ”¯æŒ**ï¼šè‡ªåŠ¨å‘ç°å’Œè§£æsitemap.xml
- **ç»“æœå­˜å‚¨**ï¼šæ”¯æŒå°†çˆ¬å–ç»“æœä¿å­˜ä¸ºJSONæ ¼å¼
- **çˆ¬è™«ç®¡ç†**ï¼šç»Ÿä¸€ç®¡ç†å¤šä¸ªçˆ¬è™«å®ä¾‹ï¼Œæ”¯æŒåˆ›å»ºã€å¯åŠ¨ã€åœæ­¢å’Œç›‘æ§

## ç³»ç»Ÿæ¶æ„

```
ç”¨æˆ· â”€â”€â†’ Webç•Œé¢(Django + Daphne ASGI)
            â”‚
            â””â”€ é…ç½®ç«™ç‚¹ (æ­£åˆ™/å‰ç¼€åŒ¹é…)
                         â”‚
                         â–¼
çˆ¬å–å™¨(Firecrawl/Httpx, Redisé˜Ÿåˆ—)
            â”‚
            â–¼
æ¸…æ´—å™¨(MarkdownConverter, Redisé˜Ÿåˆ—)
            â”‚
            â–¼
æ•°æ®åº“æŒä¹…åŒ–(PostgreSQL, URLå»é‡æ ¡éªŒ)
            â”‚â”€â”€â”€â–¶ å·²å­˜åœ¨ï¼ŒSkip
            â”‚
            â–¼ æ–°æ•°æ®æˆ–æ•°æ®æ›´æ–°
ç´¢å¼•å™¨(Llama-indexå¯¼å…¥Redis(Doc)ã€Milvus(Vector))
            â”‚
            â–¼
æœç´¢ç«¯ç‚¹(RAG)
            â”‚
            â–¼
         ç”¨æˆ·æœç´¢æŸ¥è¯¢
```

## å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### ä½¿ç”¨ç¤ºä¾‹

æˆ‘ä»¬æä¾›äº†ä¸¤ä¸ªç¤ºä¾‹è„šæœ¬ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒç±»å‹çš„çˆ¬è™«ï¼š

#### HTTPXçˆ¬è™« (æœ¬åœ°çˆ¬è™«)

```bash
# çˆ¬å–æŒ‡å®šç½‘ç«™ï¼Œæœ€å¤šçˆ¬å–10ä¸ªé¡µé¢ï¼Œæœ€å¤§æ·±åº¦ä¸º2
python examples/crawler_demo.py https://example.com

# è‡ªå®šä¹‰é…ç½®
python examples/crawler_demo.py https://example.com --id my_crawler --max-pages 20 --max-depth 3 --delay 1.0
```

#### Firecrawlçˆ¬è™« (äº‘æœåŠ¡çˆ¬è™«)

éœ€è¦å…ˆè·å–Firecrawl APIå¯†é’¥ï¼šhttps://firecrawl.dev

```bash
# è®¾ç½®APIå¯†é’¥ç¯å¢ƒå˜é‡
export FIRECRAWL_API_KEY="fc-your-api-key"

# çˆ¬å–æŒ‡å®šç½‘ç«™ï¼Œæœ€å¤šçˆ¬å–10ä¸ªé¡µé¢ï¼Œæœ€å¤§æ·±åº¦ä¸º2
python examples/firecrawl_demo.py https://example.com

# è‡ªå®šä¹‰é…ç½®
python examples/firecrawl_demo.py https://example.com --id my_crawler --max-pages 20 --max-depth 3 --formats markdown html
```

### ä»£ç ç¤ºä¾‹

```python
from src.backend.sitesearch.crawler.crawler_manager import CrawlerManager

# åˆ›å»ºçˆ¬è™«ç®¡ç†å™¨
manager = CrawlerManager(storage_dir="./crawl_results")

# åˆ›å»ºHTTPXçˆ¬è™«
manager.create_crawler(
    crawler_id="httpx_crawler",
    crawler_type="httpx",
    base_url="https://example.com",
    config={
        "max_pages": 10,
        "max_depth": 2,
        "delay": 0.5,
        "timeout": 30,
        "headers": {"User-Agent": "SiteSearch-Crawler/1.0"},
        "follow_external_links": False,
    }
)

# æˆ–è€…åˆ›å»ºFirecrawlçˆ¬è™«
manager.create_crawler(
    crawler_id="firecrawl_crawler",
    crawler_type="firecrawl",
    base_url="https://example.com",
    config={
        "api_key": "fc-your-api-key",  # ä¹Ÿå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡FIRECRAWL_API_KEYè®¾ç½®
        "max_urls": 10,
        "max_depth": 2,
        "formats": ["markdown", "html"],
    }
)

# å¯åŠ¨çˆ¬è™«
manager.start_crawler("httpx_crawler", discover_sitemap=True)

# ç­‰å¾…çˆ¬è™«å®Œæˆ
import time
while True:
    status = manager.get_crawler_status("httpx_crawler")
    print(f"çŠ¶æ€: {status['status']}, å·²çˆ¬å–: {status['stats'].get('pages_crawled', 0)}")
    
    if status["status"] not in ["running", "created"]:
        break
        
    time.sleep(2)

# ä¿å­˜ç»“æœ
result_file = manager.save_results("httpx_crawler")
print(f"ç»“æœå·²ä¿å­˜åˆ°: {result_file}")

# å…³é—­ç®¡ç†å™¨
manager.close()
```

## çˆ¬è™«ç±»å‹

ç›®å‰æ”¯æŒçš„çˆ¬è™«ç±»å‹ï¼š

- **httpx**ï¼šåŸºäºHTTPXåº“çš„æœ¬åœ°çˆ¬è™«ï¼Œé€‚ç”¨äºå¤§å¤šæ•°ç½‘ç«™
- **firecrawl**ï¼šåŸºäºFirecrawl APIçš„äº‘æœåŠ¡çˆ¬è™«ï¼Œå…·æœ‰é«˜æ€§èƒ½å’Œæ›´å¥½çš„JavaScriptæ¸²æŸ“æ”¯æŒ

## é…ç½®å‚æ•°

### é€šç”¨é…ç½®å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| max_pages / max_urls | æœ€å¤§çˆ¬å–é¡µé¢æ•° | 100 |
| max_depth | æœ€å¤§çˆ¬å–æ·±åº¦ | 3 |
| delay / request_delay | è¯·æ±‚å»¶è¿Ÿ(ç§’) | 0.5 |
| timeout | è¯·æ±‚è¶…æ—¶(ç§’) | 30 |
| headers | è¯·æ±‚å¤´ | User-Agentç­‰é»˜è®¤å€¼ |
| cookies | è¯·æ±‚Cookies | {} |
| excluded_patterns | è¦æ’é™¤çš„URLæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ | [] |
| included_patterns | è¦åŒ…å«çš„URLæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ | [] |
| proxy | ä»£ç†æœåŠ¡å™¨URL | None |

### HTTPXçˆ¬è™«ç‰¹æœ‰å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| verify_ssl | æ˜¯å¦éªŒè¯SSLè¯ä¹¦ | True |
| follow_redirects | æ˜¯å¦è·Ÿéšé‡å®šå‘ | True |
| follow_external_links | æ˜¯å¦è·Ÿéšå¤–éƒ¨é“¾æ¥ | False |

### Firecrawlçˆ¬è™«ç‰¹æœ‰å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| api_key | Firecrawl APIå¯†é’¥ | ç¯å¢ƒå˜é‡FIRECRAWL_API_KEY |
| formats | è¾“å‡ºæ ¼å¼åˆ—è¡¨ | ["markdown"] |

## æ–‡æ¡£æ¸…æ´—ç­–ç•¥

HTTPXçˆ¬è™«æ”¯æŒå¤šç§å†…å®¹æ¸…æ´—ç­–ç•¥ï¼š

- **CommonPageStrategy**ï¼šé€šç”¨ç½‘é¡µæ¸…æ´—ï¼Œè¯†åˆ«å’Œæå–ä¸»è¦å†…å®¹åŒºåŸŸ
- **MarkdownStrategy**ï¼šå°†HTMLè½¬æ¢ä¸ºMarkdownæ ¼å¼
- **HTMLStrategy**ï¼šåŸºæœ¬HTMLæ¸…æ´—ï¼Œç§»é™¤è„šæœ¬å’Œæ ·å¼
- **PlainTextStrategy**ï¼šçº¯æ–‡æœ¬æ¸…æ´—
- **PDFStrategy**ï¼šPDFæ–‡æ¡£å¤„ç†
- **DocxStrategy**ï¼šWordæ–‡æ¡£å¤„ç†
- **SearchPageStrategy**ï¼šæœç´¢é¡µé¢å¤„ç†

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰å›è°ƒå¤„ç†

æ‚¨å¯ä»¥æä¾›è‡ªå®šä¹‰å›è°ƒå‡½æ•°æ¥å¤„ç†çˆ¬å–åˆ°çš„é¡µé¢æ•°æ®ï¼š

```python
def my_page_handler(url, content, metadata):
    print(f"å¤„ç†é¡µé¢: {url}")
    # å¤„ç†å†…å®¹...

manager.create_crawler(
    crawler_id="my_crawler",
    base_url="https://example.com",
    config={...},
    callback=my_page_handler
)
```

### ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿‡æ»¤URL

```python
manager.create_crawler(
    crawler_id="my_crawler",
    base_url="https://example.com",
    config={
        "included_patterns": [r"example\.com/blog/.*"],
        "excluded_patterns": [r"example\.com/blog/tag/.*", r".*\.(jpg|png|gif)$"]
    }
)
```

## Firecrawl vs HTTPX

| ç‰¹æ€§ | Firecrawl | HTTPX |
|------|----------|-------|
| JavaScriptæ¸²æŸ“ | âœ… æ”¯æŒ | âŒ ä¸æ”¯æŒ |
| é€Ÿåº¦ | âš¡ æ›´å¿«(äº‘æœåŠ¡) | ğŸ¢ ä¸€èˆ¬(æœ¬åœ°) |
| èµ„æºæ¶ˆè€— | ğŸŒŸ ä½(äº‘æœåŠ¡) | ğŸ“ˆ é«˜(æœ¬åœ°) |
| è‡ªå®šä¹‰èƒ½åŠ› | ğŸ”’ æœ‰é™ | ğŸ”“ å®Œå…¨è‡ªå®šä¹‰ |
| æˆæœ¬ | ğŸ’° æŒ‰ä½¿ç”¨é‡æ”¶è´¹ | ğŸ†“ å…è´¹ |
| é€‚ç”¨åœºæ™¯ | ç°ä»£JavaScriptç½‘ç«™ | é™æ€ç½‘ç«™ã€å†…éƒ¨ç½‘ç»œ |

## æŠ€æœ¯ä¾èµ–

- Python 3.10+
- HTTPX
- BeautifulSoup4
- Firecrawl Pythonå®¢æˆ·ç«¯
- Redis (å¯¹äºé˜Ÿåˆ—ç®¡ç†)

## è®¸å¯è¯

MIT 